{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkkGX0S0oO3N"
   },
   "source": [
    "# Project: Dense Prediction: Monocular Depth Estimation and Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/I2rSgxd.png' width=200> <img src='https://i.imgur.com/1oP2EIg.png' width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 2\n",
    "\n",
    "## Semantic Segmentation\n",
    "\n",
    "In this part of the project, you will reuse the model you created in the previous part to perform Semantic Segmentation - instead of assigning a real number to each\n",
    "pixel , you will assign it a class.\n",
    "\n",
    "The tasks are as following:\n",
    "- Write a Dataset class that processes the segmentation data. **[10 points]**\n",
    "    - Modify the UNet model that takes an RGB image and now outputs a single channel _label map_\n",
    "    - Define an approprate loss function. **[5 points]**\n",
    "- Tune the model to achieve an mIOU of **0.45** or higher on the given validation set. **[20 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataset [10 points]\n",
    "We are going to use the [PASCAL VOC dataset](https://drive.google.com/drive/folders/1G54WDNnOQecr5T0sEvZcuyme0WT5Qje3?usp=sharing), which is a commonly used benchmark. In order to reduce the\n",
    "computational requirements, you should downsample the dataset to 256x256, similar to the previous project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now you have to implement the Dataset. Look at the file `loaders.py`.\n",
    "\n",
    "The class you will need to emulate is `class ImageDepthDataset(Dataset)`. The class is called `VOCSeg`, and it must _inherit_ from the `Dataset` class,\n",
    "just like the `ImageDepthDataset`.\n",
    "You need to fill in the `__len__` and the `__getitem__` methods.\n",
    "The `__getitem__` method should yield a dict of the RGB image and the labeled segmentation map.\n",
    "\n",
    "Make sure you downsample the image and the labels to 256x256, otherwise the training will take too much time.\n",
    "\n",
    "Make sure that the labels are in the range `0..N-1`, where\n",
    "N is the number of classes - 21 in our case. You can have one special label for unknown regions.\n",
    "\n",
    "We provide the map of RGB to label for convenience in `get_pascal_labels()`. The map should be read as this - if a pixel has color `[0, 0, 0]`, it has label 0. If the color is\n",
    "`[128, 0, 0]`, the label is 1\n",
    "\n",
    "It is also very common to change the RGB range from 0-255 to 0-1 or -1 to 1. Take a look at [torchvision.transforms.ToTensor](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.ToTensor)\n",
    "and [torchvision.transforms.Normalize](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The PASCAL VOC dataset has predefined train/val sets. Make sure your class implementation can take this _split_ as an argument. Now create train/val loaders using the `get_seg_loaders` function (look at `prep_loaders`), and we should be good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "if __name__ == '__main__':\n",
    "    from loaders import get_seg_loaders\n",
    "    train_loader, valid_loader = get_seg_loaders(root_dir='./VOC2012')\n",
    "\n",
    "    # we have read all files\n",
    "    assert len(train_loader.dataset) == 1464\n",
    "    assert len(valid_loader.dataset) == 1449"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You should implement a few more sanity checks - the range of data in the RGB part, the range of data in the label part, whether the dataset returns tensors,\n",
    "whether the labels have the datatype `torch.long` etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modifying the Loss and Architecture [5 points]\n",
    "You will have to some form of surgery on the network you constructed in Part 1.\n",
    "\n",
    "1. The number of channels the last layer predicts must change to the number of classes in the dataset.\n",
    "2. The loss function must change to reflect the fact that we are now performing per-pixel classification. (What loss did you use for classification in Project 1?)\n",
    "3. You might get a CUDA assert error. This means that you have a label higher than the number of channels in the _logits_. This is very common with semantic segmentation, where you might want to label some region unkown as it's label might be under doubt - for example near the edges of objects. Look up how to ignore a certain label with a classification loss.\n",
    "4. Take care of input label and logit sizes. We want predictions to be 256x256 as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### !! \n",
    "### <span style=\"color:red\"> At this point, we highly recommend restarting your notebook for part 2 and beginning modifying/training the  model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "learning_rate = 1\n",
    "workers = 1 # The number of parallel processes used to read data\n",
    "gpu_id = [0] # only modify if you machine has more than one GPU card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from loaders import get_seg_loaders\n",
    "    train_loader, valid_loader = get_seg_loaders(root_dir='./VOC2012')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# You can copy the depth model code with modifications here\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        #TODO Make sure you have the right number channels in the last layer\n",
    "        self.A = nn.Conv2d(3, 1, kernel_size=3, padding=1, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.A(x)\n",
    "\n",
    "def create_model_gpu():\n",
    "    model = Model()\n",
    "    model = model.cuda()\n",
    "    model = nn.DataParallel(model, device_ids=[g for g in gpu_id])\n",
    "    return model\n",
    "\n",
    "model = create_model_gpu()\n",
    "print('Ready to train.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def loss_fn(pred_y, y):\n",
    "    #TODO\n",
    "    return torch.mean(y.sub(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training and Evaluation [18 points]\n",
    "Tune the hyperparameters to get the maximum possible score on the PASCAL VOC challenge. \n",
    "And answer the following questions:\n",
    "1. What is the relationship between the _size_ of the class and the IOU How would you quantify this relationship?\n",
    "2. What is the relationship between the number of instances and the IOU? how many times a class exists in an image vs the IOU?\n",
    "3. The segmentation dataset is small. Initialize the weights of the segmentation net with the weights of the trained depth network.\n",
    "4. Which weights can you not transfer?\n",
    "5. Fine tune (ie train with a lower learning rate) the model in 3 for the same number of epochs as the model with a random initialization (or ImageNet initialized weights)\n",
    "6. What trend do you observe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_id = 'seg_model_gpu{}_n{}_bs{}_lr{}'.format(gpu_id, epochs, batch_size, learning_rate); print('\\n\\nTraining', run_id)\n",
    "save_path = run_id + '.pkl'\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "metrics = Metrics(train_loader.dataset.num_classes, train_loader.dataset.class_names)\n",
    "\n",
    "# Used to keep track of statistics\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.val = 0; self.avg = 0; self.sum = 0; self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "REPORTS_PER_EPOCH = 10\n",
    "ITER_PER_EPOCH = len(train_loader)\n",
    "ITER_PER_REPORT = ITER_PER_EPOCH//REPORTS_PER_EPOCH\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Progress reporting\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    N = len(train_loader)\n",
    "    end = time.time()\n",
    "\n",
    "    for i, (sample) in enumerate(train_loader):\n",
    "\n",
    "        # Load a batch and send it to GPU\n",
    "        x = sample['image'].float().cuda()\n",
    "        y = sample['label'].float().cuda()\n",
    "\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # Compute and print loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Record loss\n",
    "        losses.update(loss.data.item(), x.size(0))\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model).\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        eta = str(datetime.timedelta(seconds=int(batch_time.val*(N - i))))\n",
    "\n",
    "        # Log training progress\n",
    "        if i % ITER_PER_REPORT == 0:\n",
    "            print('\\nEpoch: [{0}][{1}/{2}]\\t' 'Time {batch_time.val:.3f} ({batch_time.sum:.3f})\\t' 'ETA {eta}\\t'\n",
    "             'Training Loss {loss.val:.4f} ({loss.avg:.4f})'.format(epoch, i, N, batch_time=batch_time, loss=losses, eta=eta))\n",
    "        elif i % (ITER_PER_REPORT) == 0:\n",
    "            print('.', end='')\n",
    "\n",
    "        #break # useful for quick debugging\n",
    "    torch.cuda.empty_cache(); del x, y; gc.collect()\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()\n",
    "    metrics.reset()\n",
    "    for i, (sample) in enumerate(valid_loader):\n",
    "        x, y = sample['image'].float().cuda(), sample['label'].numpy()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "            y_pred = torch.argmax(y_pred, dim=1) # get the most likely prediction\n",
    "\n",
    "        metrics.add_batch(y, y_pred.detach().cpu().numpy())\n",
    "        print('_', end='')\n",
    "    print('\\nValidation stats ', metrics.get_table())\n",
    "\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print('\\nTraining done. Model saved ({}).'.format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization  [2 points]\n",
    "Use the `decode_segmap` function to visualize images and their segmentation. The images must be from the validation set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization  [2 points]\n",
    "Use the `decode_segmap` function to visualize images and their segmentation. The images must be from the validation set.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Project_Depth_Estimate_good.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
