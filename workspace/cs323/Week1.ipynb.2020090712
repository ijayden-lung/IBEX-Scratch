{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Assignment 01\n",
    "\n",
    "*) Read the AlexNet paper \"ImageNet Classification with Deep Convolutional Neural Networks\",  Alex Krizhevsky et al. (you should find it on the internet).\n",
    "\n",
    "- Answer Questions:\n",
    "\n",
    "What are the (claimed) main ideas that lead to the success of the proposed system? Describe each main idea in a short paragraph.\n",
    "\n",
    "How does the performance of AlexNet compare to modern state-of-the-art networks on imagenet classification?\n",
    "\n",
    "How to create the AlexNet architecture using a Python command? Please show the Python command and the architecture description if you print it out using Python \n",
    "\n",
    "\n",
    "*) Look at recent conference proceedings: CVPR 2020 & ICLR 2020 & ECCV 2020. Read the abstract of 10 papers you find interesting / read part of the introduction, look at the figures, and look through the results. Don't read the complete paper, just get some main idea.\n",
    "Write down the list of 10 papers and give\n",
    "\n",
    "a) a one line description of the problem the paper tries to solve.\n",
    "\n",
    "b) one line comment what seems to be most interesting in the paper and\n",
    "\n",
    "*) Create a working Deep Learning Environment, go through the proposed tutorial, and look at the project description.\n",
    "\n",
    "Write down a list of 10 PyTorch commands you think will be beneficial for tackling project 1 / an image classification problem and give a one sentence explanation of what the commands are useful for.\n",
    "\n",
    "Submit:Submit your answers / tasks as file via blackboard.\n",
    "The file should be named A1LastnameFirstname.txt or A1LastnameFirstname.pdf\n",
    "\n",
    "A stands for assignment, 1 is the assignment number, Lastname your last name, Firstname your first name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the (claimed) main ideas that lead to the success of the proposed system? Describe each main idea in a short paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tThe five convolutional and three fully-connected layers provides learning capacity make the model more accurate.\n",
    "2.\tDropout was applied to reduce overfitting\n",
    "3.\tEfficient GPU implementation make the model training faster\n",
    "4.\tReLu was applied to make training faster and reduce overfitting \n",
    "5.\tLocal response normalization to reduce error rate\n",
    "6.\tData augmentation to reduce overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the performance of AlexNet compare to modern state-of-the-art networks on imagenet classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-1 and top-5 test set error lower than the state-of-the-art net about 8%, reach to 37.5% and 17.0% on ILSRVC-2010.\n",
    "On fall 2009 vrersion of ImageNet, they reached 67.4% and 40.9% of top-1 and top-5 error rates while the state-of-art were 78.5% and 60.9%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create the AlexNet architecture using a Python command? Please show the Python command and the architecture description if you print it out using Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 96, kernel_size=(11, 11, 3), stride=(4, 4, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(96, 256, kernel_size=(5, 5, 48), stride=(2, 2))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(256, 384, kernel_size=(3, 3, 256), stride=(1, 1))\n",
      "  (7): ReLU()\n",
      "  (8): Conv2d(384, 384, kernel_size=(3, 3, 192), stride=(1, 1))\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(384, 256, kernel_size=(3, 3, 192), stride=(1, 1))\n",
      "  (11): ReLU()\n",
      "  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): Dropout(p=0.5, inplace=True)\n",
      "  (14): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (15): ReLU()\n",
      "  (16): Dropout(p=0.5, inplace=True)\n",
      "  (17): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (18): ReLU()\n",
      "  (19): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    # 1st Convolutional Layer\n",
    "    nn.Conv2d(3, 96, kernel_size=(11,11,3), stride=4),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    \n",
    "    # 2nd Convolutional Layer\n",
    "    nn.Conv2d(96,256, kernel_size=(5,5,48),stride=2),  \n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "    \n",
    "    # 3rd Convolutional Layer\n",
    "    nn.Conv2d(256, 384, kernel_size=(3,3,256),stride=1), \n",
    "    nn.ReLU(),\n",
    "    \n",
    "    # 4th Convolutional Layer\n",
    "    nn.Conv2d(384, 384, kernel_size=(3,3,192), stride=1),  \n",
    "    nn.ReLU(),\n",
    "    \n",
    "    # 5th Convolutional Layer\n",
    "    nn.Conv2d(384, 256, kernel_size=(3,3,192), stride=1),  \n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "    \n",
    "   #3 Fully Connected layers\n",
    "    nn.Dropout(p=0.5, inplace=True),\n",
    "    nn.Linear(in_features=(256 * 6 * 6), out_features=4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5, inplace=True),\n",
    "    nn.Linear(in_features=4096, out_features=4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=4096, out_features=1000),\n",
    "    \n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *) Look at recent conference proceedings: CVPR 2020 & ICLR 2020 & ECCV 2020. Read the abstract of 10 papers you find interesting / read part of the introduction, look at the figures, and look through the results. Don't read the complete paper, just get some main idea. Write down the list of 10 papers and give\n",
    "a) a oneline description of the problem the paper tries to solve.\n",
    "b) oneline comment what seems to be most interesting in the paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. MaskFlownet: Asymmetric Feature Matching with Learnable Occlusion Mask\n",
    "    - learn a rough occlusion mask that filters useless (occluded) areas immediately after feature warping without any explicit supervision\n",
    "    - They propose to apply a multiplicative learnable occlusion mask immediately on the wrape features rather than enforcing the network to distinguish useful parts from confusing information.\n",
    "\n",
    "2. AdderNet: Do We Really Need Multiplications in Deep Learning?\n",
    "    - Reduce computation cost by trading multiplications for additions in deep neural networks.\n",
    "    - Develop a special backpropagation approach by investigating the full-precision gradient.\n",
    "3. Frequency Domain Compact 3D Convolutional Neural Networks\n",
    "    - Eliminating redundancy in the time dimensionality of 3D convolution filters by converting them into the frequency domain through a series of learned optimal transforms with extremely fewer parameters.\n",
    "    - can achieve 2x speed ratio than the state-of-art network\n",
    "4. ROAM: Recurrently Optimizing Tracking Mode\n",
    "    - Produce a heatmap indicate the object position and the shifts.\n",
    "    - The offline recurrent neural can  converge  the  model  in  a  few  gradient steps. \n",
    "\n",
    "5. Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-\n",
    "    - Generate a high-resolutions and low-motion video from a low frame rate and low-resolution video.\n",
    "    - more than3times faster on inference speed with a 4times smaller model size than the state-of-art model.\n",
    "6. Towards Universal Representation Learning for Deep Face Recognition.\n",
    "    - learn a generalized model that can directly handle new unseen domains without any model updating in face recognition.\n",
    "    - Add a meta-optimization procedure to improve model generalization.\n",
    "7. Learning to Shadow Hand-drawn Sketches\n",
    "    - generate detailed and accurate artistic shadows from pairs of line drawing sketches and lighting directions.\n",
    "    - 69% of generated sketches passed the Turing test, more than the ground truth.\n",
    "8. Circle Loss: A Unified Perspective of Pair Similarity Optimization\n",
    "    - Maximize  the within-class similarity and minimize the between-class similarity in deep feature learning.\n",
    "    - Re-weight each similarity to highlight the less-optimized similarity scores and results in a circle loss which was more flexible than the traditional loss function.\n",
    "\n",
    "9. On Robustness of Neural Ordinary Differential Equations\n",
    "    - improve the robustness properties of neural ODEs both empirically and theoretically.\n",
    "    - Their work suggest neural ODE can be used as a basic block since the robustness.\n",
    "10. Deep Fashion3D: A Dataset and Benchmark for 3D Garment Reconstruction from Single-view Images.\n",
    "    - Establishing a novel benchmark and dataset for the evaluation of image-based garment reconstruction systems.\n",
    "    - They built the largest dataset for Deep Fashion3D, a large-scale, richly annotated 3D clothing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write down a list of 10 PyTorch commands you think will be beneficial for tackling project 1 / an image classification problem and give a one sentence explanation of what the commands are useful for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a Classification Cross-Entropy loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SGD with momentum.\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the dataset multiple times\n",
    "for epoch in range(2):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the inputs; data is a list of [inputs, labels]\n",
    "inputs, labels = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # zero the parameter gradients\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward + backward + optimize\n",
    "outputs = net(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply for a CUDA device:\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
