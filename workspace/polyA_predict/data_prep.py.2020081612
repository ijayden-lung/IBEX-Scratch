#!/usr/bin/env python3

import numpy as np
import os
import sys
import argparse
from supporting import *

### Argument Parser
parser = argparse.ArgumentParser()
parser.add_argument('pos_path', help='Directory of files containing positive data')
parser.add_argument('neg_path', help='Directory of files containing negative data')
parser.add_argument('outfile', help='Save the processed dataset to')
parser.add_argument('--nfolds', default=5, type=int, help='Seperate the data into how many folds')
opts = parser.parse_args()

############Global Parameters ############
NUM_FOLDS = opts.nfolds
ALPHABET = np.array(['A', 'G', 'T', 'C'])
SPLIT_DICT = {
	'train': [i for i in range(NUM_FOLDS-2)],
	'valid': [NUM_FOLDS-2],
	'test': [NUM_FOLDS-1]
}
############Global  Parameters ############

pos_data, pos_labels, pos_pasid = get_data5(opts.pos_path, 'Positive',ALPHABET)
neg_data, neg_labels, neg_pasid = get_data5(opts.neg_path, 'Negative',ALPHABET)
randomState = np.random.RandomState(0)
pos_data, pos_labels, pos_pasid = shuffle(pos_data, pos_labels, pos_pasid, randomState)
neg_data, neg_labels, neg_pasid = shuffle(neg_data, neg_labels, neg_pasid, randomState)

dataset = data_split(pos_data, pos_labels, pos_pasid,  neg_data, neg_labels, neg_pasid, NUM_FOLDS, SPLIT_DICT)
print('Size of training dataset: %d'%dataset['train_labels'].shape[0])
print('Size of validation dataset: %d'%dataset['valid_labels'].shape[0])
print('Size of test dataset: %d\n'%dataset['test_labels'].shape[0])



np.savez(opts.outfile, **dataset)
print('Finish writing dataset to %s'%opts.outfile)

